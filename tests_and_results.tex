% !TEX root = pfc.tex

O método proposto foi implementado em forma de um \textit{software} multiplataforma, desenvolvido em linguagem \verb!C++! \citep{cplusplus:2013:online}, com intuito de obter um bom desempenho de execução e fácil implementação utilizando os conceitos de programação orientada a objetos.

Como biblioteca para processamento das imagens, foi utilizado a OpenCV 2.4.4 \citep{opencv_library}, contribuindo para que operações complexas de visão computacional pudessem ser realizadas com poucas linhas de código. O desenvolvimento do método não está preso à tecnologia escolhida, podendo ser empregado utilizando outras linguagens de programação, bem como outras bibliotecas. A tecnologia foi escolhida visando a simplicidade no processo de desenvolvimento das operações de processamento de imagens, que estão bem detalhadas pelos trechos de código na Seção \ref{sec:fluxo_de_processos}.

\section{Testes} % (fold)
\label{sec:testes}

Todos os vídeos foram capturados por um aparelho celular Samsung OMNIA W GT-I8350 \citep{omnia:2013:online}, como descrito na Seção \ref{sec:caracter_sticas_de_captura}. As imagens foram feitas na passarela localizada na Av. Presidente Carlos Luz, nos dois sentidos da via, como ilustra a Figura \ref{fig:sentidos}. Duas configurações de captura foram utilizadas:

\begin{itemize}
  \item HD 720p: gerando vídeos com resolução $1280\times 720$, e \textit{framerate} de 29 FPS;
  \item VGA: gerando vídeos com resolução $640\times 480$, e \textit{framerate} de 29 FPS.
\end{itemize}

\noindent Uma terceira resolução foi obtida a partir dos vídeos em HD, aplicando uma operação para redimensioná-los com altura e largura a metade do valor original. Essas variações de cena e resolução foram feitas com o objetivo de avaliar o comportamento do método em diferentes condições. Assim, será possível identificar o impacto de cada variável no resultado final. A Tabela \ref{tab:videos_teste} lista as amostras utilizadas.

\begin{figure}[ht]
  \begin{center}
    \begin{subfigure}[b]{.49\textwidth}
      \begin{center}
        \includegraphics[width=1\linewidth]{imgs/trackers.png}
      \end{center}
      \caption{}
      \label{fig:sentido_pampulha}
    \end{subfigure}
    \begin{subfigure}[b]{.49\textwidth}
      \begin{center}
        \includegraphics[width=1\linewidth]{imgs/sentido_centro.png}
      \end{center}
      \caption{}
      \label{fig:sentido_centro}
    \end{subfigure}
  \end{center}
  \caption{Resultado do método de contagem para dois tipos de cena. (a) Av. Carlos Luz, sentido Pampulha; (b) Av. Carlos Luz, sentido Centro.}
  \label{fig:sentidos}
\end{figure}

\begin{table}[ht]
  \caption{Vídeos utilizados nos testes.}
  \label{tab:videos_teste}
  \begin{center}
    \begin{tabular}{l|cccc}
    \hline

    \hline
    \textbf{Nome do vídeo} & \textbf{Formato} & \textbf{Resolução} & \textbf{Duração} & \textbf{FPS} \\
    \hline
      carlos\_luz\_centro\_vga & mp4 & $ 640\times 480 $ & 00:05:23 & 29 \\
      carlos\_luz\_centro\_hd\_resized & mpeg & $ 640\times 360 $ & 00:05:25 & 29 \\
      carlos\_luz\_centro\_hd & mp4 & $ 1280\times 720 $ & 00:05:29 & 29 \\
      carlos\_luz\_pampulha\_vga\_1 & mp4 & $ 640\times 480 $ & 00:05:43 & 29 \\
      carlos\_luz\_pampulha\_vga\_2 & mp4 & $ 640\times 480 $ & 00:05:19 & 29 \\
      carlos\_luz\_pampulha\_hd\_2\_resized & mpeg & $ 640\times 360 $ & 00:06:19 & 29 \\
      carlos\_luz\_pampulha\_hd\_2 & mp4 & $ 1280\times 720 $ & 00:06:21 & 29 \\
    \hline

    \hline
    \end{tabular}
  \end{center}
\end{table}

Tanto o desenvolvimento do \textit{software}, quanto os testes, foram feitos em um \textit{Laptop} Dell Vostro V131, Processador Intel Core I3-2330M (2.20GHZ, dual core 4 Threads, 3MB L3 cache), 8GB de memória RAM, em ambiente Linux Fedora 18 (Spherical Cow).

% section testes (end)

\section{Matriz de confusão} % (fold)
\label{sec:matriz_de_confus_o}

TODO: Explicar cada uma das classes: VP, VN, FP e FN; referenciar cada uma das equações;

\begin{equation}
  \label{eq:especificidade}
  E=\dfrac{VN}{VN+FP}
\end{equation}

\begin{equation}
  \label{eq:valor_preditivo_negativo}
  VPN=\dfrac{VN}{VN+FN}
\end{equation}

\begin{equation}
  \label{eq:precisao}
  P=\dfrac{VP}{VP+FP}
\end{equation}

\begin{equation}
  \label{eq:recall}
  R=\dfrac{VP}{VP+FN}
\end{equation}

\begin{equation}
  \label{eq:acuracia}
  A=\dfrac{VP+VN}{VP+FP+FN+VN}
\end{equation}

\begin{equation}
  \label{eq:f_measure}
  FM=\dfrac{2*R*P}{R+P}
\end{equation}

% section matriz_de_confus_o (end)

\section{Índice Kappa (K)} % (fold)
\label{sec:_ndice_kappa_}

TODO: falar sobre o indice kappa e fazer a referencia; referenciar a table \ref{tab:indice_kappa}.

O índice Kappa pode ser encontrado com base na Equação \ref{eq:kappa}:

\begin{equation}
  \label{eq:kappa}
  K=\dfrac{\theta_{1}-\theta_{2}}{1-\theta_{2}}\text{,}
\end{equation}

\noindent onde

\begin{equation}
  \label{eq:theta_1}
  \theta_{1}=\dfrac{VP+VN}{VP+FP+FN+VN}\text{,}
\end{equation}

\noindent e

\begin{equation}
  \label{eq:theta_2}
  \theta_{2}=\dfrac{\alpha+\beta}{\gamma^{2}}\text{,}
\end{equation}

\noindent onde $\alpha=(VP+FN)*(VP+FP)$, $\beta=(VN+FN)*(VN+FP)$ e $\gamma=VP+VN+FP+FN$.

\begin{table}[ht]
  \caption{Nível de exatidão de uma contagem, conforme o valor do índice Kappa.}
  \label{tab:indice_kappa}
  \begin{center}
    \begin{tabular}{cc}
    \hline

    \hline
    \textbf{Índice Kappa (K)} & \textbf{Qualidade} \\
    \hline
      $K \leq 0.2$ & Ruim \\
      $0.2 \leq K \leq 0.4$ & Razoável \\
      $0.4 \leq K \leq 0.6$ & Bom \\
      $0.6 \leq K \leq 0.8$ & Muito bom \\
      $K \geq 0.8$ & Excelente \\

    \hline
    \end{tabular}
  \end{center}
\end{table}

% section _ndice_kappa_ (end)

\section{Resultados finais} % (fold)
\label{sec:resultados_finais}

Na Tabela \ref{tab:resultados_contagem} são apresentados os resultados obtidos pela contagem via métodos manual e automático, indicando o percentual de acerto para cada amostra. É importante destacar que o resultado da contagem automática representa o total de veículos identificados na amostra, incluindo falsos positivos e descartando objetos detectados ou rastreados incorretamente. Portanto, os percentuais de acerto são medições estatísticas, que representam apenas o desvio existente entre o valor real e o valor medido.

\begin{table}[ht]
  \caption{Resultados de contagem volumétrica.}
  \label{tab:resultados_contagem}
  \begin{center}
    \begin{tabular}{l|cccc}
    \hline

    \hline
    \textbf{Nome do vídeo} & \textbf{Resolução} & \textbf{Manual} & \textbf{Autom.} & \textbf{\% acerto}\\
    \hline
      carlos\_luz\_centro\_vga & $ 640\times 480 $ & 164 & 156 & 95,12 \\
      carlos\_luz\_centro\_hd\_resized & $ 640\times 360 $ & 150 & 153 & 98,04 \\
      carlos\_luz\_centro\_hd & $ 1280\times 720 $ & 150 & 145 & 96,67 \\
      carlos\_luz\_pampulha\_vga\_1 & $ 640\times 480 $ & 208 & 173 & 83,17 \\
      carlos\_luz\_pampulha\_vga\_2 & $ 640\times 480 $ & 169 & 138 & 81,66 \\
      carlos\_luz\_pampulha\_hd\_2\_resized & $ 640\times 360 $ & 201 & 175 & 87,06 \\
      carlos\_luz\_pampulha\_hd\_2 & $ 1280\times 720 $ & 201 & 170 & 84,58 \\
    \hline

    \hline
    \end{tabular}
  \end{center}
\end{table}

Percebe-se que para uma mesma cena, a variação da resolução do vídeo não afeta de forma siginificativa o percentual de acerto, mostrando que vídeos de alta resolução não trazem vantagens nesse tipo de aplicação. Já a mudança da cena alterou o resultado. Nas amostras do tráfego no sentido centro o percentual de acerto foi superior a 95\%, enquanto que as imagens do outro sentido não ultrapassaram os 90\%. 

Analisando os vídeos é possível identificar vários veículos de grande porte trafegando no sentido Pampulha, muitos saindo da Fábrica da Coca-Cola ali localizada. Esses objetos com área muito grande causam problemas na etapa de subtração de \textit{background}, como mostrado na Figura \ref{fig:problema_veiculo_grande}, interferindo por alguns \textit{frames} no processo de detecção de \textit{blobs} e gerando oclusão em veículos menores. Esse tipo de tráfego na cena fez com que o resultado da contagem automática ficasse sempre abaixo da referência em todas as amostras sentido Pampulha, justificando o percentual de acerto baixo.

\begin{figure}[ht]
  \begin{center}
    \begin{subfigure}[b]{.49\textwidth}
      \begin{center}
        \includegraphics[width=1\linewidth]{imgs/problema_veiculo_grande.png}
      \end{center}
      \caption{}
      \label{fig:problema_veiculo_grande}
    \end{subfigure}
    \begin{subfigure}[b]{.49\textwidth}
      \begin{center}
        \includegraphics[width=1\linewidth]{imgs/problema_veiculo_junto.png}
      \end{center}
      \caption{}
      \label{fig:problema_veiculo_junto}
    \end{subfigure}
  \end{center}
  \caption{Problemas encontrados no processamento de imagens. (a) A operação de subtração de \textit{background} fica comprometida quando veículos com área muito grande aparecem na cena. (b) Veículos próximos são detectados como um único objeto, definindo apenas um \textit{keypoint}.}
  \label{fig:problemas}
\end{figure}

Outro tipo de problema acontece na etapa de detecção de \textit{blobs}, ilustrado na Figura \ref{fig:problema_veiculo_junto}. Nessa situação, dois veículos próximos foram identificados como um único objeto e apenas um \textit{keypoint} foi definido. Portanto, apenas um \textit{tracker} foi criado e um único veículo contado nesse caso.

Para avaliar o desempenho computacional do método adotado, mediu-se o tempo de execução do algoritmo para cada uma das amostras, como mostra a Tabela \ref{tab:resultados_tempo}. Percebe-se que a resolução do vídeo está diretamente relacionada ao tempo gasto no processamento. Os vídeos em HD foram processados com mais de três vezes o tempo de processamento dos vídeos em VGA, inviabilizando a utilização dessa configuração em aplicações de tempo real. Os vídeos redimensionados, com resolução $ 640\times 360 $, gastaram menos tempo de processamento do que sua própria duração, indicando que a contagem em tempo real nesse caso seria viável.

Com intuito de manter o algoritmo simples e o mais genérico possível, os \textit{frames} são processados por completo, sem considerar regiões de interesse. A definição de regiões de interesse, também conhecidas como ROI's\footnote{\textit{Region of interest}}, é um recurso muito utilizado em visão computacional. Quando usado, apenas as porções da imagem que contenham informações relevantes são consideradas no processamento, reduzindo o tempo e o custo computacional.

\begin{table}[ht]
  \caption{Tempo real gasto na execução do método de contagem.}
  \label{tab:resultados_tempo}
  \begin{center}
    \begin{tabular}{l|ccc}
    \hline

    \hline
    \textbf{Nome do vídeo} & \textbf{Resolução} & \textbf{Duração} & \textbf{Tempo gasto} \\
    \hline
      carlos\_luz\_centro\_vga & $ 640\times 480 $ & 00:05:23 & 00:05:47 \\
      carlos\_luz\_centro\_hd\_resized & $ 640\times 360 $ & 00:05:25 & 00:05:16 \\
      carlos\_luz\_centro\_hd & $ 1280\times 720 $ & 00:05:29 & 00:17:48 \\
      carlos\_luz\_pampulha\_vga\_1 & $ 640\times 480 $ & 00:05:43 & 00:06:04 \\
      carlos\_luz\_pampulha\_vga\_2 & $ 640\times 480 $ & 00:05:19 & 00:05:33 \\
      carlos\_luz\_pampulha\_hd\_2\_resized & $ 640\times 360 $ & 00:06:19 & 00:05:38 \\
      carlos\_luz\_pampulha\_hd\_2 & $ 1280\times 720 $ & 00:06:21 & 00:19:00 \\
    \hline

    \hline
    \end{tabular}
  \end{center}
\end{table}

% section resultados_finais (end)



























